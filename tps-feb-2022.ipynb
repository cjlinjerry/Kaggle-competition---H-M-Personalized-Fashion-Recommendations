{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preface\n\nIn this notebook I tried to follow the ML project structure from experienced kagglers step by step, and learn how they analyze the question, explore data, preprocess data, build machine learning models, evaluate results, and submit prediction. The ultimate goal is to have a pipeline for myself to prepare for future competitions.\n\nThis notebook is mainly based on the following two authorswith some of my own modification and learning notes. Thanks to [@VAD13IRT](http://www.kaggle.com/vad13irt) and [@Sanskar Hasija](https://www.kaggle.com/odins0n) for developing such high quality notebooks.\n* https://www.kaggle.com/odins0n/tps-feb-22-eda-modelling\n* https://www.kaggle.com/vad13irt/tps-2022-january-exploratory-data-analysis \n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nFor the February 2022 Tabular Playground Series competition, your task is to classify 10 different bacteria species using data from a genomic analysis technique that has some data compression and data loss. In this technique, 10-mer snippets of DNA are sampled and analyzed to give the histogram of base count. In other words, the DNA segment  becomes . Can you use this lossy information to accurately predict bacteria species?","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.ensemble import VotingClassifier\n\nimport warnings\nimport time\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\nRANDOM_STATE = 18\nFOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:34:30.638969Z","iopub.execute_input":"2022-02-26T21:34:30.639264Z","iopub.status.idle":"2022-02-26T21:34:30.651052Z","shell.execute_reply.started":"2022-02-26T21:34:30.639232Z","shell.execute_reply":"2022-02-26T21:34:30.650293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading and Preperation","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:30:59.387865Z","iopub.execute_input":"2022-02-26T21:30:59.388638Z","iopub.status.idle":"2022-02-26T21:31:26.126999Z","shell.execute_reply.started":"2022-02-26T21:30:59.388595Z","shell.execute_reply":"2022-02-26T21:31:26.126229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Train Data","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n\nüìå <b><u>Observations in Train Data</u></b><br>\n\n* There are <b><u>288</u></b> columns: <b><u>286</u></b> continous, <b><u>1</u></b> row_id, and <b><u>1</u></b> target column<br>\n* There are total of <b><u>200,000</u></b> rows in train dataset<br>\n* <b><u>\"target\"</u></b> is the target variable with <b><u>10</u></b> possible values<br>\n* There are no missing / null values in this dataset\n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"### Quick view of Train Data","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:22.738367Z","iopub.execute_input":"2022-02-26T20:24:22.738633Z","iopub.status.idle":"2022-02-26T20:24:22.849656Z","shell.execute_reply.started":"2022-02-26T20:24:22.738598Z","shell.execute_reply":"2022-02-26T20:24:22.849055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'\\033[92mNumber of rows in train data: {train.shape[0]}')\nprint(f'\\033[94mNumber of columns in train data: {train.shape[1]}')\nprint(f'\\033[91mNumber of observations in train data: {train.count().sum()}')\nprint(f'\\033[91mNumber of missing values in train data: {sum(train.isnull().sum())}')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:22.850685Z","iopub.execute_input":"2022-02-26T20:24:22.851495Z","iopub.status.idle":"2022-02-26T20:24:23.139808Z","shell.execute_reply.started":"2022-02-26T20:24:22.851461Z","shell.execute_reply":"2022-02-26T20:24:23.138827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic statistics of training data\nBelow is the basic statistics for each variables in the training dataset, which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile`, and `maximum`.","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:23.142183Z","iopub.execute_input":"2022-02-26T20:24:23.142561Z","iopub.status.idle":"2022-02-26T20:24:25.575935Z","shell.execute_reply.started":"2022-02-26T20:24:23.142518Z","shell.execute_reply":"2022-02-26T20:24:25.575235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Test Data","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Test Data</u></b><br>\n\n* There are <b><u>287</u></b> columns: <b><u>286</u></b> continous, and <b><u>1</u></b> row_id<br>\n* There are total of <b><u>100,000</u></b> rows in train dataset<br>\n* There are no missing / null values in this dataset\n    \n</div>","metadata":{}},{"cell_type":"code","source":"print(f'\\033[92mNumber of rows in train data: {test.shape[0]}')\nprint(f'\\033[94mNumber of columns in train data: {test.shape[1]}')\nprint(f'\\033[91mNumber of observations in train data: {test.count().sum()}')\nprint(f'\\033[91mNumber of missing values in train data: {sum(test.isnull().sum())}')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:25.576963Z","iopub.execute_input":"2022-02-26T20:24:25.577304Z","iopub.status.idle":"2022-02-26T20:24:25.713372Z","shell.execute_reply.started":"2022-02-26T20:24:25.577275Z","shell.execute_reply":"2022-02-26T20:24:25.712564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Quick view of Test Data","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:25.714802Z","iopub.execute_input":"2022-02-26T20:24:25.715259Z","iopub.status.idle":"2022-02-26T20:24:25.830791Z","shell.execute_reply.started":"2022-02-26T20:24:25.715218Z","shell.execute_reply":"2022-02-26T20:24:25.830193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic statistics of test data\nBelow is the basic statistics for each variables in the test dataset, which contain information on `count`, `mean`, `standard deviation`, `minimum`, `1st quartile`, `median`, `3rd quartile`, and `maximum`.","metadata":{}},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:25.831952Z","iopub.execute_input":"2022-02-26T20:24:25.832283Z","iopub.status.idle":"2022-02-26T20:24:27.30989Z","shell.execute_reply.started":"2022-02-26T20:24:25.832253Z","shell.execute_reply":"2022-02-26T20:24:27.309207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission File","metadata":{}},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:27.311067Z","iopub.execute_input":"2022-02-26T20:24:27.311438Z","iopub.status.idle":"2022-02-26T20:24:27.420661Z","shell.execute_reply.started":"2022-02-26T20:24:27.311395Z","shell.execute_reply":"2022-02-26T20:24:27.419863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing & Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n\n‚úçÔ∏è <b><u>Check List</u></b><br>\n\nBasic information<br>\n* Does one hot encoding needed for categorical variables?<br>\n* Check missing values (drop or impute?)<br>\n* Check duplicates (drop?)<br>\n\nEDA<br>\n* Check target distribution (balance or imbalance)<br>\n* Check normal distribution for numeric columns<br>\n* Check correlation<br>\n* Detect outliers<br>\n* Test any assumptions\n    \n</div>","metadata":{}},{"cell_type":"code","source":"train.drop('row_id', axis = 1, inplace = True)\ntest.drop('row_id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:27.422082Z","iopub.execute_input":"2022-02-26T20:24:27.422332Z","iopub.status.idle":"2022-02-26T20:24:27.626319Z","shell.execute_reply.started":"2022-02-26T20:24:27.422299Z","shell.execute_reply":"2022-02-26T20:24:27.625498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overview of Data","metadata":{}},{"cell_type":"code","source":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='YlOrRd')\\\n                     .bar(subset=[\"max\"], color='#969696')\\\n                     .bar(subset=[\"mean\",], color='#585858')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:27.630268Z","iopub.execute_input":"2022-02-26T20:24:27.630558Z","iopub.status.idle":"2022-02-26T20:24:30.428537Z","shell.execute_reply.started":"2022-02-26T20:24:27.630529Z","shell.execute_reply":"2022-02-26T20:24:30.427876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Null Distribution","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Null Distribution</u></b><br>\n\n* No Null values\n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"## Duplicate Values","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Duplicated Data</u></b><br>\n\n* There are 76,007 duplicated records in the Train dataset<br>\n* Based on Kaggle employee, the duplicated records in this competition came from data generated process, which should not be excluded for the analysis\n    \n</div>","metadata":{}},{"cell_type":"code","source":"train.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:30.42976Z","iopub.execute_input":"2022-02-26T20:24:30.43051Z","iopub.status.idle":"2022-02-26T20:24:31.748836Z","shell.execute_reply.started":"2022-02-26T20:24:30.430473Z","shell.execute_reply":"2022-02-26T20:24:31.747905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target Distribution","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Target Distribution</u></b><br>\n\n* There are <b>10</b> different target values<br>\n* All target values are equally distributed approx - 10% of total observations for each target.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"sns.set_style('whitegrid')\nfig = plt.figure(figsize = (12, 4))\nax = fig.add_subplot(1, 1, 1)\n\nsns.countplot(x = 'target', data = train, palette=\"Set2\")\nplt.xticks(rotation=15)\n\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\n\nax.set_xlabel(\"target\", fontsize=14, labelpad=10)\nax.set_ylabel(\"Count\", fontsize=14, labelpad=10)\nax.set_title('Target Distribution', loc = 'left', fontsize = 20, fontweight = 'bold')\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:31.750452Z","iopub.execute_input":"2022-02-26T20:24:31.750734Z","iopub.status.idle":"2022-02-26T20:24:32.256486Z","shell.execute_reply.started":"2022-02-26T20:24:31.750696Z","shell.execute_reply":"2022-02-26T20:24:32.255776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Distribution","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Feature Distribution</u></b><br>\n\n* Most features are skewed to the left<br>\n* Some features have very low variances (unique values <= 30)\n                                                            \n</div>","metadata":{}},{"cell_type":"code","source":"numeric_columns = train.columns[train.dtypes == 'float64'].to_numpy()\nlen(numeric_columns)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:32.25756Z","iopub.execute_input":"2022-02-26T20:24:32.25853Z","iopub.status.idle":"2022-02-26T20:24:32.265607Z","shell.execute_reply.started":"2022-02-26T20:24:32.25849Z","shell.execute_reply":"2022-02-26T20:24:32.264859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (17, 1.5 * len(numeric_columns)))\nrows = 143\ncols = 2\n\nfor idx, numeric_column in enumerate(numeric_columns):\n  ax = fig.add_subplot(rows, cols, idx + 1)\n  sns.kdeplot(x = numeric_column, data = train, fill = True, alpha = 0.6, linewidth = 0.7, edgecolor = '#000', label = 'Train')\n  sns.kdeplot(x = numeric_column, data = test, fill = True, alpha = 0.6, linewidth = 0.7, edgecolor = '#000', label = 'Test')\n\n  ax.xaxis.set_tick_params(labelsize=10, size=0, pad=5)\n  ax.yaxis.set_tick_params(labelsize=10, size=0, pad=5)\n\n  ax.spines['right'].set_visible(False)\n  ax.spines['top'].set_visible(False)\n\n  if idx % cols == 0:\n    ax.set_ylabel('Density')\n  else:\n    ax.set_ylabel('')\n\n  ax.set_xlabel(numeric_column)\n  ax.legend()\n\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:24:32.266935Z","iopub.execute_input":"2022-02-26T20:24:32.267179Z","iopub.status.idle":"2022-02-26T20:30:49.834118Z","shell.execute_reply.started":"2022-02-26T20:24:32.267146Z","shell.execute_reply":"2022-02-26T20:30:49.833285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 143\ncols = 2\nfig = plt.figure(figsize = (17, 1.5 * len(numeric_columns)))\n\nfor idx, numeric_column in enumerate(numeric_columns):\n  ax = fig.add_subplot(rows, cols, idx + 1)\n  sns.kdeplot(x = numeric_column, data = train, hue = 'target', fill = True, alpha = 0.5, linewidth = 0.7, edgecolor = '#000')\n \n  ax.xaxis.set_tick_params(labelsize=10, size=0, pad=5)\n  ax.yaxis.set_tick_params(labelsize=10, size=0, pad=5)\n\n  ax.spines['right'].set_visible(False)\n  ax.spines['top'].set_visible(False)\n\n  if idx % cols == 0:\n    ax.set_ylabel('Density')\n  else:\n    ax.set_ylabel('')\n\n  ax.set_xlabel(numeric_column)\n\n  if (idx + 1) != 2:\n    ax.legend([])\n\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:30:49.835709Z","iopub.execute_input":"2022-02-26T20:30:49.83615Z","iopub.status.idle":"2022-02-26T20:39:55.35147Z","shell.execute_reply.started":"2022-02-26T20:30:49.836106Z","shell.execute_reply":"2022-02-26T20:39:55.350479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nfig.set_facecolor(\"#fff\")\nax = fig.add_subplot()\nax.set_facecolor(\"#fff\")\n\ncorr = train[numeric_columns].corr()\nsns.heatmap(corr, annot=False, cmap='magma')\nax.xaxis.set_tick_params(labelsize=8, size=0, pad=5)\nax.yaxis.set_tick_params(labelsize=8, size=0, pad=5)\nax.set_title(\"Pearson Correlation\", loc=\"left\", fontsize=25, fontweight=\"bold\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:39:55.353118Z","iopub.execute_input":"2022-02-26T20:39:55.353362Z","iopub.status.idle":"2022-02-26T20:40:37.317483Z","shell.execute_reply.started":"2022-02-26T20:39:55.353331Z","shell.execute_reply":"2022-02-26T20:40:37.316786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[numeric_columns].nunique().sort_values(ascending = False).tail(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:40:37.318468Z","iopub.execute_input":"2022-02-26T20:40:37.318715Z","iopub.status.idle":"2022-02-26T20:40:38.1018Z","shell.execute_reply.started":"2022-02-26T20:40:37.318682Z","shell.execute_reply":"2022-02-26T20:40:38.101099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"low_variance_columns = train[numeric_columns].nunique().sort_values(ascending = False).tail(10).index.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:40:38.103013Z","iopub.execute_input":"2022-02-26T20:40:38.103257Z","iopub.status.idle":"2022-02-26T20:40:38.856963Z","shell.execute_reply.started":"2022-02-26T20:40:38.103223Z","shell.execute_reply":"2022-02-26T20:40:38.856143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize = (17, 1.5 * 5))\n\nfor idx, low_variance_column in enumerate(low_variance_columns):\n  ax = plt.subplot(5, 2, idx + 1)\n\n  sns.boxplot(x = low_variance_column, data = train)\n\n  ax.set_ylabel(low_variance_column, rotation = 0)\n\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:40:38.858403Z","iopub.execute_input":"2022-02-26T20:40:38.858666Z","iopub.status.idle":"2022-02-26T20:40:41.65937Z","shell.execute_reply.started":"2022-02-26T20:40:38.858628Z","shell.execute_reply":"2022-02-26T20:40:41.658686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Basic Feature Engineering","metadata":{}},{"cell_type":"code","source":"TARGET = 'target'\nFEATURES = [col for col in train.columns if col not in ['row_id', TARGET]]\n\n'''\ntrain[\"mean\"] = train[FEATURES].mean(axis=1)\ntrain[\"std\"] = train[FEATURES].std(axis=1)\ntrain[\"min\"] = train[FEATURES].min(axis=1)\ntrain[\"max\"] = train[FEATURES].max(axis=1)\n\ntest[\"mean\"] = test[FEATURES].mean(axis=1)\ntest[\"std\"] = test[FEATURES].std(axis=1)\ntest[\"min\"] = test[FEATURES].min(axis=1)\ntest[\"max\"] = test[FEATURES].max(axis=1)\n\nFEATURES.extend(['mean', 'std', 'min', 'max'])\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:40:41.660581Z","iopub.execute_input":"2022-02-26T20:40:41.660894Z","iopub.status.idle":"2022-02-26T20:40:41.668795Z","shell.execute_reply.started":"2022-02-26T20:40:41.660857Z","shell.execute_reply":"2022-02-26T20:40:41.667014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n    \nüìå <b><u>Observations in Modelling</u></b><br>\n\n* <i> <u><b>LGBMClassifier</b></u> , <u><b>CatBoostClassifier</b></u> and <u><b>XGBClassifier</b></u> used in modelling on 5-fold validation.\n\n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\n\ntrain[TARGET] = encoder.fit_transform(train[TARGET])\n\nX = train[TARGET].values\ny = train[FEATURES].values","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:05:00.836527Z","iopub.execute_input":"2022-02-26T21:05:00.837147Z","iopub.status.idle":"2022-02-26T21:05:01.174701Z","shell.execute_reply.started":"2022-02-26T21:05:00.837111Z","shell.execute_reply":"2022-02-26T21:05:01.173928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class = \"alert alert-info\" role = \"alert\"; style=\"font-size:14px; font-family:verdana;\">\n\n‚úçÔ∏è <u><b>Train Test Split and Cross Validation</b></u><br>\n\nScikit-learn library provides many tools to split data into training and test sets. The most basic one is train_test_split which just divides the data into two parts according to the specified partitioning ratio.<br>\n\nIf we split data using train_test_split, we can only train a model with the portion set aside for training. The models get better as the amount of training data increases. One solution to overcome this issue is cross validation. With cross validation, dataset is divided into n splits. N-1 split is used for training and the remaining split is used for testing. The model runs through the entire dataset n times and at each time, a different split is used for testing. Thus, we use all of data points for both training and testing. Cross validation is also useful to measure the performance of a model more accurately, especially on new, previously unseen data points.<br>\n\nThere are different methods to split data in cross validation. KFold and StratifiedKFold are commonly used.<br>\n\nAs the name suggests, KFold divides the dataset into k folds.<br>\n\nStratifiedKFold takes the cross validation one step further. The class distribution in the dataset is preserved in the training and test splits.<br>\n\nIn classifications tasks with imbalanced class distributions, we should prefer StratifiedKFold over KFold.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:40:41.810645Z","iopub.execute_input":"2022-02-26T20:40:41.810951Z","iopub.status.idle":"2022-02-26T20:40:41.8191Z","shell.execute_reply.started":"2022-02-26T20:40:41.810913Z","shell.execute_reply":"2022-02-26T20:40:41.818356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost Classifier\n\nDocumentation - https://xgboost.readthedocs.io/en/stable/parameter.html#general-parameters\n\n<i>When predictor is set to default value auto, the gpu_hist tree method is able to provide GPU based prediction without copying training data to GPU memory. If gpu_predictor is explicitly specified, then all data is copied into GPU, only recommended for performing prediction tasks.</i>\n\n","metadata":{}},{"cell_type":"code","source":"xgb_params = {\n    'objective': 'multi:softmax', # For multiclass classification\n    'eval_metric': 'mlogloss',    # Default to multiclass classification\n    'tree_method': 'gpu_hist',    # Equivalent to the XGBoost fast histogram algorithm. Much faster and uses considerably less memory.\n    'predictor': 'gpu_predictor', # Prediction using GPU. Used when tree_method is gpu_hist.\n    'booster': 'gbtree',          # Default value\n    'eta': 0.3,                   # Learning rate, default = 0.3\n    'gamma': 0,                   # min_split_loss, default = 0\n    'max_depth': 6,               # Maximum depth of a tree, default = 6\n    'lambda': 1,                  # L2 regularization term on weights, default = 1\n    'alpha': 0,                   # L1 regularization term on weights, default = 0\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:05:23.649345Z","iopub.execute_input":"2022-02-26T21:05:23.65003Z","iopub.status.idle":"2022-02-26T21:05:23.656853Z","shell.execute_reply.started":"2022-02-26T21:05:23.649994Z","shell.execute_reply":"2022-02-26T21:05:23.656036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_predictions = []\nxgb_scores = []\nxgb_fimp = []\n\ncv = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(cv.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold = {fold + 1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train, y_valid = train[TARGET].iloc[train_idx], train[TARGET].iloc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params) # Use ** to pass a dictionary for parameters\n    model.fit(X_train, y_train, verbose = 0)\n    \n    pred_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid, pred_valid)\n    xgb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold = {fold + 1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    test_pred = model.predict(test[FEATURES])\n    fim = pd.DataFrame(index = FEATURES,\n                      data = model.feature_importances_,\n                      columns = [f'{fold}_importance'])\n    xgb_fimp.append(fim)\n    xgb_predictions.append(test_pred)\n    \nprint(\"Mean Accuracy :\", np.mean(xgb_scores))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:05:30.613078Z","iopub.execute_input":"2022-02-26T21:05:30.61333Z","iopub.status.idle":"2022-02-26T21:06:50.808458Z","shell.execute_reply.started":"2022-02-26T21:05:30.6133Z","shell.execute_reply":"2022-02-26T21:06:50.807646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance for XGBoost Classifier (Top 15 Features)","metadata":{}},{"cell_type":"code","source":"xgb_fis_df = pd.concat(xgb_fimp, axis = 1).head(15)\nxgb_fis_df.sort_values('1_importance').plot(kind = 'barh', figsize = (15, 10), title = 'Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:42:03.632025Z","iopub.execute_input":"2022-02-26T20:42:03.632304Z","iopub.status.idle":"2022-02-26T20:42:04.082933Z","shell.execute_reply.started":"2022-02-26T20:42:03.632264Z","shell.execute_reply":"2022-02-26T20:42:04.082239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM Classifier\n\nDocumentation - https://lightgbm.readthedocs.io/en/latest/Parameters.html","metadata":{}},{"cell_type":"code","source":"lgb_params = {\n    'objective': 'multiclass',    # For multiclass classification\n    'metric': 'multi_logloss',    # For multiclass classification\n    'device': 'gpu',              # Use GPU\n    'num_iterations': 100,        # Same as num_tree, n_iter, n_estimators. Default = 100\n    'learning_rate': 0.1,         # Same as eta, default = 0.1\n    'num_leaves': 31,             # Default = 31\n    'max_depth': -1,              # Default = -1\n    'bagging_freq': 0,            # 0 = disable bagging, default = 0\n    'feature_fraction': 1,        # Randomly select n% of features on each iteration\n    'lambda_l1': 0,               # Default = 0\n    'lambda_l2': 0,               # Default = 0\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:10:28.499829Z","iopub.execute_input":"2022-02-26T21:10:28.500128Z","iopub.status.idle":"2022-02-26T21:10:28.505785Z","shell.execute_reply.started":"2022-02-26T21:10:28.500093Z","shell.execute_reply":"2022-02-26T21:10:28.504908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_predictions = []\nlgb_scores = []\nlgb_fimp = []\n\ncv = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(cv.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold = {fold + 1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train, y_valid = train[TARGET].iloc[train_idx], train[TARGET].iloc[valid_idx]\n    \n    model = LGBMClassifier(**lgb_params)\n    model.fit(X_train, y_train, verbose = 0)\n    \n    pred_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid, pred_valid)\n    lgb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold = {fold + 1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    test_pred = model.predict(test[FEATURES])\n    fim = pd.DataFrame(index = FEATURES,\n                      data = model.feature_importances_,\n                      columns = [f'{fold}_importance'])\n    lgb_fimp.append(fim)\n    lgb_predictions.append(test_pred)\n    \nprint(\"Mean Accuracy :\", np.mean(lgb_scores))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:10:29.292773Z","iopub.execute_input":"2022-02-26T21:10:29.293405Z","iopub.status.idle":"2022-02-26T21:16:15.232048Z","shell.execute_reply.started":"2022-02-26T21:10:29.293345Z","shell.execute_reply":"2022-02-26T21:16:15.231292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance for LGBM Classifier (Top 15 Features)","metadata":{}},{"cell_type":"code","source":"lgbm_fis_df = pd.concat(lgb_fimp, axis = 1).head(15)\nlgbm_fis_df.sort_values('1_importance').plot(kind = 'barh', figsize = (15, 10), title = 'Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:16:15.233782Z","iopub.execute_input":"2022-02-26T21:16:15.234032Z","iopub.status.idle":"2022-02-26T21:16:15.672877Z","shell.execute_reply.started":"2022-02-26T21:16:15.233997Z","shell.execute_reply":"2022-02-26T21:16:15.67223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Catboost Classifier","metadata":{}},{"cell_type":"markdown","source":"Documentation - https://catboost.ai/en/docs/references/training-parameters/","metadata":{}},{"cell_type":"code","source":"catb_params = {\n    'objective': \"MultiClass\",       # For multiclass classification\n    \"task_type\": \"GPU\",              # Use GPU\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:16:15.674307Z","iopub.execute_input":"2022-02-26T21:16:15.674787Z","iopub.status.idle":"2022-02-26T21:16:15.678651Z","shell.execute_reply.started":"2022-02-26T21:16:15.674749Z","shell.execute_reply":"2022-02-26T21:16:15.677713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catb_predictions = []\ncatb_scores = []\ncatb_fimp = []\n\ncv = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(cv.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold = {fold + 1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train, y_valid = train[TARGET].iloc[train_idx], train[TARGET].iloc[valid_idx]\n    \n    model = CatBoostClassifier(**catb_params)\n    model.fit(X_train, y_train, verbose = 0)\n    \n    pred_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid, pred_valid)\n    catb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold = {fold + 1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    test_pred = model.predict(test[FEATURES])\n    fim = pd.DataFrame(index = FEATURES,\n                      data = model.feature_importances_,\n                      columns = [f'{fold}_importance'])\n    catb_fimp.append(fim)\n    catb_predictions.append(test_pred)\n    \nprint(\"Mean Accuracy :\", np.mean(catb_scores))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:16:15.680877Z","iopub.execute_input":"2022-02-26T21:16:15.681142Z","iopub.status.idle":"2022-02-26T21:18:29.014935Z","shell.execute_reply.started":"2022-02-26T21:16:15.681107Z","shell.execute_reply":"2022-02-26T21:18:29.014075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance for LGBM Classifier (Top 15 Features)","metadata":{}},{"cell_type":"code","source":"catb_fis_df = pd.concat(catb_fimp, axis = 1).head(15)\ncatb_fis_df.sort_values('1_importance').plot(kind = 'barh', figsize = (15, 10), title = 'Feature Importance Across Folds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:18:29.016202Z","iopub.execute_input":"2022-02-26T21:18:29.016499Z","iopub.status.idle":"2022-02-26T21:18:29.44997Z","shell.execute_reply.started":"2022-02-26T21:18:29.016457Z","shell.execute_reply":"2022-02-26T21:18:29.449244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble Model","metadata":{}},{"cell_type":"code","source":"vote_predictions = []\nvote_scores = []\n\ncv = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(cv.split(train[FEATURES], train[TARGET])):\n    \n    print(10*\"=\", f\"Fold = {fold + 1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][FEATURES], train.iloc[valid_idx][FEATURES]\n    y_train, y_valid = train[TARGET].iloc[train_idx], train[TARGET].iloc[valid_idx]\n    \n    model = VotingClassifier(\n            estimators = [\n                ('XGB_model', XGBClassifier(**xgb_params)),\n                ('LGBM_model', LGBMClassifier(**lgb_params)),\n                ('CatBoost_model', CatBoostClassifier(**catb_params))],\n            voting = 'soft'\n            )\n    \n    model.fit(X_train, y_train)\n    \n    pred_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid, pred_valid)\n    vote_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    print(f\"Fold = {fold + 1}, Accuracy: {acc:.2f}, Run Time: {run_time:.2f}s\")\n    test_pred = model.predict(test[FEATURES])\n\n    vote_predictions.append(test_pred)\n    \nprint(\"Mean Accuracy :\", np.mean(vote_scores))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:45:45.631749Z","iopub.execute_input":"2022-02-26T21:45:45.632409Z","iopub.status.idle":"2022-02-26T21:55:00.373772Z","shell.execute_reply.started":"2022-02-26T21:45:45.632347Z","shell.execute_reply":"2022-02-26T21:55:00.372955Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submission[['row_id']]","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:31:26.128776Z","iopub.execute_input":"2022-02-26T21:31:26.129197Z","iopub.status.idle":"2022-02-26T21:31:26.135648Z","shell.execute_reply.started":"2022-02-26T21:31:26.129156Z","shell.execute_reply":"2022-02-26T21:31:26.13477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_submission = submission.copy()\nxgb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(xgb_predictions),axis = 1)[0]).astype('int'))\nxgb_submission.to_csv(\"xgb-subs.csv\",index=False)\nxgb_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:32:37.965455Z","iopub.execute_input":"2022-02-26T21:32:37.965713Z","iopub.status.idle":"2022-02-26T21:32:40.93897Z","shell.execute_reply.started":"2022-02-26T21:32:37.965685Z","shell.execute_reply":"2022-02-26T21:32:40.938114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_submission = submission.copy()\nlgb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(lgb_predictions),axis = 1)[0]).astype('int'))\nlgb_submission.to_csv(\"lgb-subs.csv\",index=False)\nlgb_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T20:51:01.209448Z","iopub.execute_input":"2022-02-26T20:51:01.209857Z","iopub.status.idle":"2022-02-26T20:51:01.216991Z","shell.execute_reply.started":"2022-02-26T20:51:01.209817Z","shell.execute_reply":"2022-02-26T20:51:01.215932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catb_submission = submission.copy()\ncatb_submission[\"target\"] = encoder.inverse_transform(np.squeeze(mode(np.column_stack(catb_predictions),axis = 1)[0]).astype('int'))\ncatb_submission.to_csv(\"catb.csv\",index=False)\ncatb_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T21:32:47.689755Z","iopub.execute_input":"2022-02-26T21:32:47.69001Z","iopub.status.idle":"2022-02-26T21:32:50.637071Z","shell.execute_reply.started":"2022-02-26T21:32:47.68998Z","shell.execute_reply":"2022-02-26T21:32:50.636277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_submission = submission.copy()\npred_mode = encoder.inverse_transform(np.squeeze(mode(np.column_stack(xgb_predictions + lgb_predictions + catb_predictions),axis = 1)[0]).astype('int'))\nmode_submission[\"target\"] = pred_mode\nmode_submission.to_csv(\"pred_mode.csv\",index=False)\nmode_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T22:04:15.655191Z","iopub.execute_input":"2022-02-26T22:04:15.655456Z","iopub.status.idle":"2022-02-26T22:04:18.734812Z","shell.execute_reply.started":"2022-02-26T22:04:15.655425Z","shell.execute_reply":"2022-02-26T22:04:18.734125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_submission = submission.copy()\nvote_pred = encoder.inverse_transform(np.squeeze(mode(np.column_stack(vote_predictions),axis = 1)[0]).astype('int'))\nvote_submission[\"target\"] = vote_pred\nvote_submission.to_csv(\"pred_vote.csv\",index=False)\nvote_submission.head()","metadata":{},"execution_count":null,"outputs":[]}]}